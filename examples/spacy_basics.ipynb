{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set your own project path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set path to project -> change if needed\n",
    "project_path = '/Users/EB/Google Drive/Projects/breweries'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import needed modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# modules\n",
    "import pickle\n",
    "import spacy\n",
    "import os\n",
    "\n",
    "# change directory and load Beer class\n",
    "os.chdir(project_path + '/modules/')\n",
    "\n",
    "from beeradvocate.classes import Beer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create \"custom\" spacy pipeline (would also be standard)\n",
    "def spacy_pipe(nlp):\n",
    "    return(nlp.tagger, nlp.parser, nlp.entity)\n",
    "\n",
    "# Load custom pipeline for English\n",
    "nlp = spacy.load('en', create_pipeline = spacy_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at one beer review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load pickled beer reviews\n",
    "os.chdir(project_path + '/data/')\n",
    "beers = pickle.load(open('reviews_sample.p', 'rb'))\n",
    "\n",
    "# start with one review to check functionality\n",
    "review = beers[0].reviews[0][0]\n",
    "review = nlp(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['strong', 'sweet', 'aroma', 'chocolate', 'coffee', 'barley', 'dark', 'black', 'pour', 'creamy', 'head', 'beer', 'standard', 'porter', 'taste', 'chocolate', 'coffee', 'touch', 'earthy', 'spice', 'nutmeg', 'cinnamon', 'thick', 'stout', 'good', 'beer', 'sam', 'one', 'good', 'year', 'glad', 'available', '6-pack', 'same', 'old', 'fezziwig']\n"
     ]
    }
   ],
   "source": [
    "# Lemmatize the review and keep only (proper) nouns and adjectives\n",
    "# This might be \"enough\" pre-processing for e.g. cluster analysis\n",
    "lemmas = []\n",
    "for word in review:\n",
    "    if word.pos_ in ('NOUN', 'PROPN', 'ADJ'):\n",
    "        lemmas.append(word.lemma_)\n",
    "\n",
    "print(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* * 11/21/12 strong sweet aroma\n",
      "dark black pour\n",
      "creamy head\n",
      "the beer\n",
      "standard porter taste\n",
      ", plus a touch\n",
      "earthy spice\n",
      "thick , almost a stout\n",
      "a really good beer\n",
      "this one\n",
      "the year\n",
      "a 6-pack\n",
      "old fezziwig\n"
     ]
    }
   ],
   "source": [
    "# Parser\n",
    "# Extract noun chunks in the text (with length > 1)\n",
    "# Note: if dependency parsing is not needed, use:\n",
    "#       spacy.load('en', parser = False) to increase speed\n",
    "for np in review.noun_chunks:\n",
    "    if len(np) > 1:\n",
    "        print(np.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these dependencies (e.g. \"creamy head\", \"earthy spice\") are more interesting than others (e.g. \"this one\"). \n",
    "We can use a rule based system to extract them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dark black pour\n",
      "creamy head\n",
      "standard porter taste\n",
      "earthy spice\n",
      "old fezziwig\n"
     ]
    }
   ],
   "source": [
    "for np in review.noun_chunks:\n",
    "    toks = [token.pos_ for token in np]\n",
    "    tok_count = toks.count('PROPN') + toks.count('NOUN') + toks.count('ADJ')\n",
    "\n",
    "    if  tok_count == len(toks) & len(toks) > 1:\n",
    "        print(np.lemma_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
